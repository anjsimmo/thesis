Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Neville2010,
abstract = {Play based sports monitoring techniques provide coaches and players with the tools to better measure the effects of training or live performance. This paper explores the advantages of using accelerometers units, in an effort to better analyse over ground running in professional athletes. A large portion of studies in player monitoring in the Australian Football League (AFL) utilize GPS to obtain time and distance measurements.},
author = {Neville, Jonathon and Wixted, Andrew and Rowlands, David and James, Daniel},
booktitle = {Proceedings of the 2010 6th International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)},
doi = {10.1109/ISSNIP.2010.5706766},
isbn = {9781424471768},
keywords = {AFL,Acceleration,Australian Football League,Frequency measurement,GPS,Games,Global Positioning System,Monitoring,Stride frequency,Training,accelerometer sensors,accelerometers,gait analysis,linear relationship,overground running data,player monitoring,professional athletes,sensors,sport,sports equipment,sports monitoring,treadmill,underutilized resource,velocity 4 km/h to 24 km/h},
mendeley-groups = {recent-work-post-submission},
mendeley-tags = {AFL,Acceleration,Australian Football League,Frequency measurement,GPS,Games,Global Positioning System,Monitoring,Stride frequency,Training,accelerometer sensors,accelerometers,gait analysis,linear relationship,overground running data,player monitoring,professional athletes,sensors,sport,sports equipment,sports monitoring,treadmill,underutilized resource,velocity 4 km/h to 24 km/h},
month = {dec},
pages = {287--290},
shorttitle = {Accelerometers},
title = {{Accelerometers: An underutilized resource in sports monitoring}},
year = {2010}
}
@techreport{Keefe2017,
author = {O'Keefe, Christine M. and Otorepec, Stephanie and Elliot, Mark and Mackey, Elaine and O'Hara, Kieron},
file = {:home/andrew/static/mendeley-pdfs/recent-work-post-submission/csiro-de-identification-decision-making-framework.pdf:pdf},
institution = {CSIRO},
mendeley-groups = {recent-work-post-submission},
number = {EP173122 and EP175702},
title = {{The De-Identification Decision-Making Framework}},
url = {https://publications.csiro.au/rpr/download?pid=csiro:EP173122{\&}dsid=DS3},
year = {2017}
}
@article{Hull2006,
abstract = {Taverna is an application that eases the use and integration of the growing number of molecular biology tools and databases available on the web, especially web services. It allows bioinformaticians to construct workflows or pipelines of services to perform a range of different analyses, such as sequence analysis and genome annotation. These high-level workflows can integrate many different resources into a single analysis. Taverna is available freely under the terms of the GNU Lesser General Public License (LGPL) from http://taverna.sourceforge.net/.},
author = {Hull, Dunca and Wolstencroft, Katy and Stevens, Robert and Goble, Carole and Pocock, Mathew R. and Li, Peter and Oinn, Tom},
doi = {10.1093/nar/gkl320},
issn = {03051048},
journal = {Nucleic Acids Research},
month = {jul},
number = {suppl{\_}2},
pages = {W729--W732},
pmid = {16845108},
shorttitle = {Taverna},
title = {{Taverna: A tool for building and running workflows of services}},
url = {https://academic.oup.com/nar/article/34/suppl{\_}2/W729/2505722/Taverna-a-tool-for-building-and-running-workflows},
volume = {34},
year = {2006}
}
@article{Cervone2016,
abstract = {Basketball games evolve continuously in space and time as players constantly interact with their teammates, the opposing team, and the ball. However, current analyses of basketball outcomes rely on discretized summaries of the game that reduce such interactions to tallies of points, assists, and similar events. In this paper, we propose a framework for using optical player tracking data to estimate, in real time, the expected number of points obtained by the end of a possession. This quantity, called $\backslash$textit{\{}expected possession value{\}} (EPV), derives from a stochastic process model for the evolution of a basketball possession; we model this process at multiple levels of resolution, differentiating between continuous, infinitesimal movements of players, and discrete events such as shot attempts and turnovers. Transition kernels are estimated using hierarchical spatiotemporal models that share information across players while remaining computationally tractable on very large data sets. In addition to estimating EPV, these models reveal novel insights on players' decision-making tendencies as a function of their spatial strategy.},
archivePrefix = {arXiv},
arxivId = {1408.0777},
author = {Cervone, Daniel and D'Amour, Alex and Bornn, Luke and Goldsberry, Kirk},
doi = {10.1080/01621459.2016.1141685},
eprint = {1408.0777},
isbn = {8750142011},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {.g.i.basketball,Competing risks,Gaussian process,Optical tracking data,Spatiotemporal model,XY research},
mendeley-tags = {.g.i.basketball,XY research},
month = {apr},
number = {514},
pages = {585--599},
title = {{A Multiresolution Stochastic Process Model for Predicting Basketball Possession Outcomes}},
url = {http://dx.doi.org/10.1080/01621459.2016.1141685},
volume = {111},
year = {2016}
}
@article{Baker2016,
abstract = {A Nature survey lifts the lid on how researchers view the ‘crisis' rocking science and what they think will help.},
author = {Baker, Monya and Penny, Dan},
doi = {10.1038/533452A},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker, Penny - 2016 - Is there a reproducibility crisis.pdf:pdf},
isbn = {1476-4687},
issn = {14764687},
journal = {Nature},
keywords = {Folder - scientific{\_}reproducability},
mendeley-tags = {Folder - scientific{\_}reproducability},
month = {may},
number = {7604},
pages = {452--454},
pmid = {27225100},
title = {{Is there a reproducibility crisis?}},
url = {http://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970},
volume = {533},
year = {2016}
}
@article{Wolpert1996,
abstract = {This is the first of two papers that use off-training set {\{}(OTS){\}} error to investigate the assumption-free relationship between learning algorithms. This first paper discusses the senses in which there are no {\{}$\backslash$textbackslash{\}}textita priori distinctions between learning algorithms. {\{}(The{\}} second paper discusses the senses in which there are such distinctions.) In this first paper it is shown, loosely speaking, that for any two algorithms A and B, there are “as many” targets (or priors over targets) for which A has lower expected {\{}OTS{\}} error than B as vice-versa, for loss functions like zero-one loss. In particular, this is true if A is cross-validation and B is “anti-cross-validation” (choose the learning algorithm with largest cross-validation error). This paper ends with a discussion of the implications of these results for computational learning theory. It is shown that one can not say: if empirical misclassification rate is low; the {\{}Vapnik-Chervonenkis{\}} dimension of your generalizer is small; and the training set is large, then with high probability your {\{}OTS{\}} error is small. Other implications for “membership queries” algorithms and “punting” algorithms are also discussed.},
author = {Wolpert, David H.},
doi = {10.1162/neco.1996.8.7.1341},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolpert - 1996 - The Lack of A Priori Distinctions Between Learning Algorithms.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural Computation},
number = {7},
pages = {1341--1390},
title = {{The Lack of A Priori Distinctions Between Learning Algorithms}},
url = {https://www.mitpressjournals.org/doi/10.1162/neco.1996.8.7.1341},
volume = {8},
year = {1996}
}
@article{Anderson2011,
abstract = {Effectively evaluating visualization techniques is a difficult task often assessed through feedback from user studies and expert evaluations. This work presents an alternative approach to visualization evaluation in which brain activity is passively recorded using electroencephalography (EEG). These measurements are used to compare different visualization techniques in terms of the burden they place on a viewer's cognitive resources. In this paper, EEG signals and response times are recorded while users interpret different representations of data distributions. This information is processed to provide insight into the cognitive load imposed on the viewer. This paper describes the design of the user study performed, the extraction of cognitive load measures from EEG data, and how those measures are used to quantitatively evaluate the effectiveness of visualizations. {\textcopyright} 2011 The Author(s).},
author = {Anderson, E. W. and Potter, K. C. and Matzen, L. E. and Shepherd, J. F. and Preston, G. A. and Silva, C. T.},
doi = {10.1111/j.1467-8659.2011.01928.x},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson et al. - 2011 - A user study of visualization effectiveness using EEG and cognitive load.pdf:pdf},
isbn = {1467-8659},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Categories and Subject Descriptors (according to A,Electroencephalography,Evaluation,General-Human Factors,I.3.3 [Computer Graphics],cognitive load,visualisation},
mendeley-tags = {cognitive load,visualisation},
number = {3},
pages = {791--800},
title = {{A user study of visualization effectiveness using EEG and cognitive load}},
volume = {30},
year = {2011}
}
@incollection{Voelter2013,
abstract = {This book covers DSL Design, Implementation and Use of DSL in detail. It consists of four parts. Part 1 introduces DSLs in general and discusses their advantages and drawbacks. It also defines important terms and concepts and introduces the case studies used in the most of the re-mainder of the book. Part 2 discusses the design of DSLs – independent of implementation techniques. It discusses seven design dimensions, explains a number of reusable language paradigms and points out a number of process-related issues. Part 3 provides details about the implementation of DSLs with lots of code. It uses three state-of-the-art but quite different language workbenches: Jet-Brains MPS, Eclipse Xtext and TU Delft's Spoofax. Part 4 discusses the use of DSLs for requirements, architecture, implementation and product line engineering, as well as their roles as a developer utility and for implementing business logic.},
author = {Voelter, Markus},
booktitle = {DSL Engineering: Designing, Implementing and Using Domain-Specific Languages},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Voelter - 2013 - Introduction to DSLs.pdf:pdf},
isbn = {978-1481218580},
keywords = {DSL},
mendeley-tags = {DSL},
title = {{Introduction to DSLs}},
url = {http://voelter.de/dslbook/markusvoelter-dslengineering-1.0.pdf},
year = {2013}
}
@article{Ryan2011,
author = {Ryan, Danny},
journal = {Coaching Edge},
keywords = {Folder - lit{\_}count{\_}analysis},
mendeley-tags = {Folder - lit{\_}count{\_}analysis},
month = {dec},
number = {2},
shorttitle = {AFL Community},
title = {{The five fundamentals of modern football}},
url = {http://www.aflcommunityclub.com.au/index.php?id=811},
volume = {25},
year = {2011}
}
@article{Moody2009,
abstract = {Visual notations form an integral part of the language of software engineering (SE). Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation. In evaluating and comparing notations, details of visual syntax are rarely discussed. In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought. Typically, no design rationale, scientific or otherwise, is provided for visual representation choices. While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax. This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving. Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties. The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate. They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones. The paper identifies serious design flaws in some of the leading SE notations, together with practical suggestions for improving them. It also showcases some examples of visual notation design excellence from SE and other fields.},
author = {Moody, Daniel},
doi = {10.1109/TSE.2009.67},
isbn = {978-1-60558-719-6},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Analysis,Communication,Computer industry,Concrete,Concrete syntax,Design optimization,Diagrams,Flowcharts,Humans,Modeling,Physics,Problem-solving,Software engineering,Unified modeling language,Visual syntax,Visualization,analysis,communication,concrete syntax.,design flaws,diagrams,physics of notations,visual notations,visual representation,visual syntax},
mendeley-tags = {Computer industry,Concrete,Design optimization,Flowcharts,Humans,Modeling,Physics,Problem-solving,Software engineering,Unified modeling language,Visualization,analysis,communication,concrete syntax.,design flaws,diagrams,physics of notations,visual notations,visual representation,visual syntax},
month = {nov},
number = {6},
pages = {756--779},
shorttitle = {The {\#}x0201C;Physics {\#}x0201D; of Notations},
title = {{The physics of notations: Toward a scientific basis for constructing visual notations in software engineering}},
volume = {35},
year = {2009}
}
@article{LeHoang2017,
abstract = {1 2017 Presented : Data- Driven Hoang . Le 1 , Peter 2 , Yisong 1 , and 3 California 1 , Disney 2 , and 3},
author = {Le, Hoang M. and Peter, Carr and Yue, Yisong},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le, Peter, Yue - 2017 - Data-Driven Ghosting using Deep Imitation Learning.pdf:pdf},
journal = {MIT Sloan Sports Analytics Conference},
keywords = {.c.d.geo,.g.i.soccer,Data Preparation,Disney,LSTM,Neural Networks},
mendeley-tags = {.c.d.geo,.g.i.soccer,Data Preparation,Disney,LSTM,Neural Networks},
pages = {1--15},
title = {{Data-Driven Ghosting using Deep Imitation Learning}},
url = {https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20170228130457/Data-Driven-Ghosting-using-Deep-Imitation-Learning-Paper1.pdf},
year = {2017}
}
@article{Ramchurn2016,
abstract = {Major natural or man-made disasters such as Hurricane Katrina or the 9/11 terror attacks pose significant challenges for emergency responders. First, they have to develop an understanding of the unfolding event either using their own resources or through third-parties such as the local population and agencies. Second, based on the information gathered, they need to deploy their teams in a flexible manner, ensuring that each team performs tasks in The most effective way. Third, given the dynamic nature of a disaster space, and the uncertainties involved in performing rescue missions, information about the disaster space and the actors within it needs to be managed to ensure that responders are always acting on up-to-date and trusted information. Against this background, this paper proposes a novel disaster response system called HAC-ER. Thus HAC-ER interweaves humans and agents, both robotic and software, in social relationships that augment their individual and collective capabilities. To design HAC-ER, we involved end-users including both experts and volunteers in a several participatory design workshops, lab studies, and field trials of increasingly advanced prototypes of individual components of HAC-ER as well as the overall system. This process generated a number of new quantitative and qualitative results but also raised a number of new research questions. HAC-ER thus demonstrates how such Human-Agent Collectives (HACs) can address key challenges in disaster response. Specifically, we show how HAC-ER utilises crowdsourcing combined with machine learning to obtain most important situational awareness from large streams of reports posted by members of the public and trusted organisations. We then show how this information can inform human-agent teams in coordinating multi-UAV deployments, as well as task planning for responders on the ground. Finally, HAC-ER incorporates an infrastructure and the associated intelligence for tracking and utilising the provenance of information shared across the entire system to ensure its accountability. We individually validate each of these elements of HAC-ER and show how they perform against standard (non-HAC) baselines and also elaborate on the evaluation of the overall system.},
author = {Ramchurn, Sarvapali D. and Huynh, Trung Dong and Wu, Feng and Ikuno, Yukki and Flann, Jack and Moreau, Luc and Fischer, Joel E. and Jiang, Wenchao and Rodden, Tom and Simpson, Edwin and Reece, Steven and Roberts, Stephen and Jennings, Nicholas R.},
doi = {10.1613/jair.5098},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramchurn et al. - 2016 - A Disaster Response System based on Human-Agent Collectives.pdf:pdf},
isbn = {145033413X},
issn = {1076-9757},
journal = {Journal of Artificial Intelligence Research},
keywords = {disaster response,human and agents,innovative applications},
month = {dec},
pages = {661--708},
title = {{A Disaster Response System based on Human-Agent Collectives}},
url = {https://jair.org/index.php/jair/article/view/11037 http://dl.acm.org/citation.cfm?id=2772879.2772947{\%}5Cnhttp://www.scopus.com/inward/record.url?eid=2-s2.0-84944679264{\&}partnerID=40{\&}md5=6e3ef6855fb68739e56226c582b4e9cb},
volume = {57},
year = {2016}
}
@article{Corbett2019,
abstract = {In team-sport, physical and skilled output is often described via aggregate parameters including total distance and number of skilled involvements. However, the degree to which these output change throughout a team-sport match, as a function of time, is relatively unknown. This study aimed to identify and describe segments of physical and skilled output in team-sport matches with an example in Australian Football. The relationship between the number of change points and level of similarity was also quantified. A binary segmentation algorithm was applied to the velocity time series, collected via wearable sensors, of 37 Australian football players (age: 23 ± 4 years, height: 187 ± 8 cm, mass: 86 ± 9 kg). A change point quotient of between 1 and 15 was used. For these quotients, descriptive statistics, spectral features and a sum of skilled involvements were extracted. Segment similarity for each quotient was evaluated using a random forest model. The strongest classification features in the model were spectral entropy and skewness. Offensive and defensive involvements were the weakest features for classification, suggesting skilled output is dependent on match circumstances. The methodology presented may have application in comparing the specificity of training to matches and designing match rotation strategies.},
author = {Corbett, David M. and Sweeting, Alice J. and Robertson, Sam},
doi = {10.1080/02640414.2019.1577941},
file = {:home/andrew/static/mendeley-pdfs/corbett2019-A change point approach to analysing the match activity profiles of team sport athletes.pdf:pdf},
issn = {0264-0414},
journal = {Journal of Sports Sciences},
keywords = {GPS,Performance analysis,gps,performance analysis,signal processing,sport,sport statistics,statistics,time series analysis},
month = {feb},
pages = {1--9},
publisher = {Routledge},
title = {{A change point approach to analysing the match activity profiles of team-sport athletes}},
url = {https://www.tandfonline.com/doi/full/10.1080/02640414.2019.1577941},
year = {2019}
}
@article{Gudmundsson2014,
abstract = {Analysing a football match is without doubt an important task for coaches, talent scouts, players and even media; and with current technologies more and more match data is collected. Several companies offer the ability to track the position of the players and the ball with high accuracy and high resolution. They also offer software that include basic analysis tools, for example basic statistics about distance run and number of passes. It is, however, a non-trivial task to perform more advanced analysis. We present a collection of tools that we developed specifically for analysing the performance of football players and teams. The aim, functionality and the underlying algorithms for each tool are presented and discussed. {\textcopyright} 2013.},
author = {Gudmundsson, Joachim and Wolle, Thomas},
doi = {10.1016/j.compenvurbsys.2013.09.004},
isbn = {9781450316910},
issn = {01989715},
journal = {Computers, Environment and Urban Systems},
keywords = {.c.vid,.f.cs,.g.i.soccer,.l.player,.l.team,.m.quant.event,.m.quant.spat,.m.quant.temp,.p.mod.clustering,.p.mod.rule.association-rules,.p.mod.voronoi,.p.obj.game.passing,.p.vis.spatial.dominant-regions,.t.e,ALGORITHMS,Algorithms,Data structures,Folder - lit{\_}spatiotemporal,Football,Movement analysis,Spatio-temporal analysis},
mendeley-tags = {.c.vid,.f.cs,.g.i.soccer,.l.player,.l.team,.m.quant.event,.m.quant.spat,.m.quant.temp,.p.mod.clustering,.p.mod.rule.association-rules,.p.mod.voronoi,.p.obj.game.passing,.p.vis.spatial.dominant-regions,.t.e,ALGORITHMS,Data structures,Folder - lit{\_}spatiotemporal,Football,Movement analysis,Spatio-temporal analysis},
month = {sep},
pages = {16--27},
series = {Progress in Movement Analysis - Experiences with Real Data},
title = {{Football analysis using spatio-temporal tools}},
url = {http://www.sciencedirect.com/science/article/pii/S0198971513000847},
volume = {47},
year = {2014}
}
@article{Jankun-Kelly2007,
abstract = {Visualization exploration is the process of extracting insight from data via interaction with visual depictions of that data. Visualization exploration is more than presentation; the interaction with both the data and its depiction is as important as the data and depiction itself. Significant visualization research has focused on the generation of visualizations (the depiction); less effort has focused on the exploratory aspects of visualization (the process). However, without formal models of the process, visualization exploration sessions cannot be fully utilized to assist users and system designers. Toward this end, we introduce the P-Set Model of Visualization Exploration for describing this process and a framework to encapsulate, share, and analyze visual explorations. In addition, systems utilizing the model and framework are more efficient as redundant exploration is avoided. Several examples drawn from visualization applications demonstrate these benefits. Taken together, the model and framework provide an effective means to exploit the information within the visual exploration process.},
author = {Jankun-Kelly, T. J. and Ma, Kwan-Liu and Gertz, Michael},
doi = {10.1109/TVCG.2007.28},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jankun-Kelly, Ma, Gertz - 2007 - A Model and Framework for Visualization Exploration.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Index Terms—Visualization exploration process,XML,collaboration,derivation,history,science of visualization,software framework,visualization,visualization systems},
number = {2},
pages = {357--369},
title = {{A Model and Framework for Visualization Exploration}},
url = {https://ieeexplore.ieee.org/ielx5/2945/4069227/04069243.pdf?tp={\&}arnumber=4069243{\&}isnumber=4069227},
volume = {13},
year = {2007}
}
@article{Williams2009,
abstract = {This investigation quantified Horizontal Positioning Error (HPE) from stationary Global Positioning System (GPS) units. In experiment 1, GPS units were placed within close proximity of each other and data were collected at three times within the same day. In experiment 2, the GPS units were configured in a straight line from the edge of the field (nearby to a stadium), towards the centre. Circular Error Probable of 95{\%} (CEP95) was used to quantify HPE, mean numbers of satellites recorded. CEP95 and the number of satellites were inversely related in both experiments. Changes in satellite availability throughout the day led to significant variability in HPE across trials},
author = {Williams, Morgan and Morgan, Stuart},
doi = {10.1080/24748668.2009.11868483},
issn = {2474-8668},
journal = {International Journal of Performance Analysis in Sport},
keywords = {Circle Error Probable,Global Positioning System,Multipath Effects,gps,stadium},
mendeley-tags = {Circle Error Probable,Global Positioning System,Multipath Effects,gps,stadium},
month = {aug},
number = {2},
pages = {275--280},
shorttitle = {Horizontal positioning error derived from stationa},
title = {{Horizontal positioning error derived from stationary GPS units: A function of time and proximity to building infrastructure}},
url = {https://www.tandfonline.com/doi/full/10.1080/24748668.2009.11868483},
volume = {9},
year = {2009}
}
@incollection{schneider2009moving,
abstract = {The field of moving objectsmoving object databases (G{\"{u}}ting and Schneider 2005) has received a lot of research interest in recent years. This technology enables the user to model, store, retrieve, and query the movements of spatial objects over time, called moving objects, and to ask queries about such movements in a database context. A moving object represents the continuous evolution of a spatial object over time. In some cases, only the time-dependent locations are of interest, and we speak of moving pointsmoving point. Examples are mobile phone users, whales, ships, planes, terrorists, cars, spacecrafts, satellites, and missiles. In other cases, also the time-dependent shape and/or areal extent, which can grow or shrink, need to be handled, and we speak of moving regions.},
author = {Schneider, Markus},
booktitle = {Lecture Notes in Geoinformation and Cartography},
doi = {10.1007/978-3-540-88244-2_12},
isbn = {9783540882442},
issn = {18632351},
number = {199069},
pages = {169--187},
publisher = {Springer},
shorttitle = {Moving objects in databases and gis},
title = {{Moving Objects in Databases and GIS: State-of-the-Art and Open Problems}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-88244-2{\_}12},
year = {2009}
}
@article{Pearl2009,
abstract = {This reviewpresents empirical researcherswith recent advances in causal inference, and stresses the paradigmatic shifts that must be un- dertaken in moving fromtraditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that un- derly all causal inferences, the languages used in formulating those assump- tions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coher- entmathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the effects of potential interven- tions, (also called “causal effects” or “policy evaluation”) (2) queries about probabilities of counterfactuals, (including assessment of “regret,” “attri- bution” or “causes of effects”) and (3) queries about direct and indirect effects (also known as “mediation”). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.},
archivePrefix = {arXiv},
arxivId = {arXiv:1112.1788v3},
author = {Pearl, Judea},
doi = {10.1214/09-SS057},
eprint = {arXiv:1112.1788v3},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearl - 2009 - Causal inference in statistics An overview.pdf:pdf},
isbn = {1935-7516},
issn = {1935-7516},
journal = {Statistics Surveys},
keywords = {and phrases,causal effects,causes of effects,confounding,counterfactuals,graph-,ical methods,mediation,policy evaluation,potential-outcome,received september 2009,structural equation models},
number = {0},
pages = {96--146},
pmid = {25246403},
title = {{Causal inference in statistics: An overview}},
url = {http://projecteuclid.org/euclid.ssu/1255440554},
volume = {3},
year = {2009}
}
@article{oshaughnessy_possession_2006,
abstract = {In sports like Australian Rules football and soccer, teams must battle to achieve possession of the ball in sufficient space to make optimal use of it. Ultimately the teams need to score, and to do that the ball must be brought into the area in front of goal – the place where the defence usually concentrates on shutting down space and opportunity time. Coaches would like to quantify the trade-offs between contested play in good positions and uncontested play in less promising positions, in order to inform their decisionmaking about where to put their players, and when to gamble on sending the ball to a contest rather than simply maintain possession. To evaluate football strategies, Champion Data has collected the on-ground locations of all 350,000 possessions and stoppages in the past two seasons of AFL (2004, 2005). By following each chain of play through to the next score, we can now reliably estimate the scoreboard “equity” of possessing the ball at any location, and measure the effect of having sufficient time to dispose of it effectively. As expected, winning the ball under physical pressure (through a “hard ball get”) is far more difficult to convert into a score than winning it via a mark. We also analyse some equity gradients to show how getting the ball 20 metres closer to goal is much more important in certain areas of the ground than in others. We conclude by looking at the choices faced by players in possession wanting to maximise their likelihood of success.},
author = {O'Shaughnessy, Darren M},
issn = {13032968},
journal = {Journal of Sports Science and Medicine},
keywords = {.c.human,.f.cs,.g.i.afl,.l.player,.l.team,.m.quant.event,.m.quant.spat,.m.quant.temp,.p.lev.tactics,.p.mod.equity,.p.opt.g,.p.vis.spatial.heat-map,.t.e,.t.p,Australian Rules Football,Folder - lit{\_}intro,Folder - lit{\_}spatiotemporal,Notational analysis,Tactical coaching},
mendeley-tags = {.c.human,.f.cs,.g.i.afl,.l.player,.l.team,.m.quant.event,.m.quant.spat,.m.quant.temp,.p.lev.tactics,.p.mod.equity,.p.opt.g,.p.vis.spatial.heat-map,.t.e,.t.p,Folder - lit{\_}intro,Folder - lit{\_}spatiotemporal},
number = {4},
pages = {533--540},
pmid = {24357947},
shorttitle = {Possession versus position},
title = {{Possession Versus position: Strategic evaluation in AFL}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3861752/},
volume = {5},
year = {2006}
}
@article{Goodstadt2010,
abstract = {SUMMARY: Computational pipelines are common place in scientific research. However, most of the resources for constructing pipelines are heavyweight systems with graphical user interfaces. Ruffus is a library for the creation of computational pipelines. Its lightweight and unobtrusive design recommends it for use even for the most trivial of analyses. At the same time, it is powerful enough to have been used for complex workflows involving more than 50 interdependent stages. Availability and implementation: Ruffus is written in python. Source code, a short tutorial, examples and a comprehensive user manual are freely available at http://www.ruffus.org.uk. The example program is available at http://www.ruffus.org.uk/examples/bioinformatics},
author = {Goodstadt, Leo},
doi = {10.1093/bioinformatics/btq524},
isbn = {1367-4811 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {pipeline},
mendeley-tags = {pipeline},
month = {sep},
number = {21},
pages = {2778--2779},
pmid = {20847218},
shorttitle = {Ruffus},
title = {{Ruffus: A lightweight Python library for computational pipelines}},
url = {http://bioinformatics.oxfordjournals.org/content/early/2010/09/16/bioinformatics.btq524},
volume = {26},
year = {2010}
}
@book{Coventry2015,
author = {Coventry, James},
isbn = {9780733333699},
keywords = {.g.i.afl},
mendeley-tags = {.g.i.afl},
publisher = {HarperCollins Publishers},
title = {{Time and Space: Footy Tactics from Origins to AFL}},
type = {Book},
year = {2015}
}
@book{Lewis2004,
abstract = {Moneyball is a quest for the secret of success in baseball. Following the low-budget Oakland Athletics, their larger-than-life general manger, Billy Beane, and the strange brotherhood of amateur baseball enthusiasts, Michael Lewis has written not only "the single most influential baseball book ever" (Rob Neyer, Slate) but also what "may be the best book ever written on business" (Weekly Standard).},
address = {New York},
author = {Lewis, Michael},
edition = {1st editio},
isbn = {0393324818},
keywords = {Folder - lit{\_}count,statistics},
language = {English},
mendeley-tags = {Folder - lit{\_}count},
month = {mar},
pages = {320},
publisher = {W. W. Norton {\&} Company},
shorttitle = {Moneyball},
title = {{Moneyball: The Art of Winning an Unfair Game}},
year = {2004}
}
@article{Clements,
author = {Clements, Matti},
journal = {Sports Coach, Australian Sports Commission},
number = {2},
shorttitle = {Sports Coach},
title = {{How to get your group to become a team}},
url = {https://web.archive.org/web/20151102065854/http://www.ausport.gov.au/sportscoachmag/psychology2/how{\_}to{\_}get{\_}your{\_}group{\_}to{\_}become{\_}a{\_}team},
volume = {29}
}
@incollection{andrienko_visualization_2014,
abstract = {Space–time cube is often used as a visualization technique representing trajectories of moving objects in (geographic) space and time by three display dimensions (H{\"{a}}gerstrand 1970). Despite the recent advances allowing space–time cube visualization of clusters of trajectories, it is problematic to represent trajectory attributes. We propose a new time transformation—sequential ordering—that transforms the space–time cube into a new display, trajectory wall, which allows effective and efficient visualization of trajectory attributes for trajectories following similar routes. To enable temporal analysis regarding temporal cycles, we use a time lens technique for interactive visualization. We demonstrate the work of the method on a real data set with trajectories of cars in a big city.},
author = {Andrienko, Gennady and Andrienko, Natalia and Schumann, Heidrun and Tominski, Christian},
booktitle = {Cartography from Pole to Pole SE - 11},
doi = {10.1007/978-3-642-32618-9_11},
isbn = {978-3-642-32617-2},
keywords = {Geographical Information Systems/Cartography,Information Systems and Communication Service,Movement data,Space–time cube,Trajectories,Trajectory wall,trajectories},
mendeley-tags = {Geographical Information Systems/Cartography,Information Systems and Communication Service,Movement data,Space–time cube,Trajectory wall,trajectories},
pages = {157--163},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Geoinformation and Cartography},
title = {{Visualization of Trajectory Attributes in Space--Time Cube and Trajectory Wall}},
url = {http://dx.doi.org/10.1007/978-3-642-32618-9{\_}11},
year = {2014}
}
@article{Oinn2004,
abstract = {MOTIVATION: In silico experiments in bioinformatics involve the co-ordinated use of computational tools and information repositories. A growing number of these resources are being made available with programmatic access in the form of Web services. Bioinformatics scientists will need to orchestrate these Web services in workflows as part of their analyses. RESULTS: The Taverna project has developed a tool for the composition and enactment of bioinformatics workflows for the life sciences community. The tool includes a workbench application which provides a graphical user interface for the composition of workflows. These workflows are written in a new language called the simple conceptual unified flow language (Scufl), where by each step within a workflow represents one atomic task. Two examples are used to illustrate the ease by which in silico experiments can be represented as Scufl workflows using the workbench application.},
author = {Oinn, Tom and Addis, Matthew and Ferris, Justin and Marvin, Darren and Senger, Martin and Greenwood, Mark and Carver, Tim and Glover, Kevin and Pocock, Matthew R. and Wipat, Anil and Li, Peter},
doi = {10.1093/bioinformatics/bth361},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oinn et al. - 2004 - Taverna A tool for the composition and enactment of bioinformatics workflows.pdf:pdf},
isbn = {1367-4803 (Print)},
issn = {13674803},
journal = {Bioinformatics},
month = {nov},
number = {17},
pages = {3045--3054},
pmid = {15201187},
shorttitle = {Taverna},
title = {{Taverna: A tool for the composition and enactment of bioinformatics workflows}},
url = {https://academic.oup.com/bioinformatics/article/20/17/3045/186405/Taverna-a-tool-for-the-composition-and-enactment},
volume = {20},
year = {2004}
}
@article{Huang2009,
abstract = {Graph visualizations are typically evaluated by comparing their differences in effectiveness, measured by task performance such as response time and accuracy. Such performance-based measures have proved to be useful in their own right. There are some situations, however, where the perfor- mance measures alone may not be sensitive enough to detect differences. This limitation can be seen from the fact that the graph viewer may achieve the same level of performance by devoting different amounts of cognitive effort. In addition, it is not often that individual performance measures are consis- tently in favor of a particular visualization. This makes design and evaluation difficult in choosing one visualization over another. In an attempt to over- come the above-mentioned limitations,we measure the effectiveness of graph visualizations from a cognitive load perspective. Human memory as an infor- mation processing system and recent results from cognitive load research are reviewed first. The construct of cognitive load in the context of graph visual- ization is proposed and discussed. A model of user task performance, mental effort and cognitive load is proposed thereafter to further reveal the inter- acting relations between these three concepts. A cognitive load measure called mental effort is introduced and this measure is further combined with tradi- tional performance measures into a single multi-dimensional measure called visualization efficiency. The proposed model and measurements are tested in a user study for validity. Implications of the cognitive load considerations in graph},
author = {Huang, Weidong and Eades, Peter and Hong, Seok Hee},
doi = {10.1057/ivs.2009.10},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Eades, Hong - 2009 - Measuring effectiveness of graph visualizations A cognitive load perspective.pdf:pdf},
isbn = {1473-8716},
issn = {14738716},
journal = {Information Visualization},
keywords = {Cognitive load,Evaluation,Graph visualization,Visualization effectiveness,Visualization efficiency,cognitive load,visualisation},
mendeley-tags = {cognitive load,visualisation},
number = {3},
pages = {139--152},
pmid = {23295103},
title = {{Measuring effectiveness of graph visualizations: A cognitive load perspective}},
volume = {8},
year = {2009}
}
@inproceedings{Jackson2008,
author = {Jackson, Karl},
booktitle = {Mathematics and Computers in Sport},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jackson - 2008 - A player rating syatem for Australian Rules Football using field equity measures.pdf:pdf},
keywords = {.g.i.afl,Champion Data,Equity,draft pick,individual perforamcne,multi-level models,team performance},
mendeley-tags = {.g.i.afl,Champion Data,Equity},
title = {{A player rating syatem for Australian Rules Football using field equity measures}},
year = {2008}
}
@article{Werner1996,
abstract = {Purpose of this article is to inform teachers about current models of teaching games in the public schools. Technical model is outlined. Followed by the history of an emerging model of teaching games called the understanding approach.},
author = {Werner, Peter and Thorpe, Rod and Bunker, David},
doi = {10.1080/07303084.1996.10607176},
issn = {0730-3084},
journal = {Journal of Physical Education, Recreation {\&} Dance},
keywords = {.f.ss,.g,.l.skill,.p.lev.training,.p.obj.understanding,.t.e,Education--Teaching Methods And Curriculum,Folder - lit{\_}intro,Games,Learning,Physical Fitness And Hygiene,Physical education,Public Health And Safety,Public schools,Sports And Games},
mendeley-tags = {.f.ss,.g,.l.skill,.p.lev.training,.p.obj.understanding,.t.e,Education--Teaching Methods And Curriculum,Folder - lit{\_}intro,Games,Learning,Physical Fitness And Hygiene,Physical education,Public Health And Safety,Public schools,Sports And Games},
month = {jan},
number = {1},
pages = {28--33},
shorttitle = {Teaching games for understanding},
title = {{Teaching Games for Understanding: Evolution of a Model}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07303084.1996.10607176},
volume = {67},
year = {1996}
}
@inproceedings{Zaheer2017,
abstract = {We study the problem of designing models for machine learning tasks defined on $\backslash$emph{\{}sets{\}}. In contrast to traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets that are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics $\backslash$cite{\{}poczos13aistats{\}}, to anomaly detection in piezometer data of embankment dams $\backslash$cite{\{}Jung15Exploration{\}}, to cosmology $\backslash$cite{\{}Ntampaka16Dynamical,Ravanbakhsh16ICML1{\}}. Our main theorem characterizes the permutation invariant functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We also derive the necessary and sufficient conditions for permutation equivariance in deep models. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection.},
archivePrefix = {arXiv},
arxivId = {1703.06114},
author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R. and Smola, Alexander J.},
booktitle = {Advances in Neural Information Processing Systems (NIPS 2017)},
eprint = {1703.06114},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaheer et al. - 2017 - Deep Sets.pdf:pdf},
issn = {10495258},
keywords = {Neural Network,permutation invariant,sets},
mendeley-tags = {Neural Network,permutation invariant,sets},
title = {{Deep Sets}},
url = {http://arxiv.org/abs/1703.06114},
year = {2017}
}
@book{Quinlan1993,
author = {Quinlan, J. Ross},
publisher = {Morgan Kaufmann Publishers},
title = {{C4.5: Programs for Machine Learning}},
year = {1993}
}
@article{Gudmundsson2016,
abstract = {Team-based invasion sports such as football, basketball and hockey are similar in the sense that the players are able to move freely around the playing area; and that player and team performance cannot be fully analysed without considering the movements and interactions of all players as a group. State of the art object tracking systems now produce spatio-temporal traces of player trajectories with high definition and high frequency, and this, in turn, has facilitated a variety of research efforts, across many disciplines, to extract insight from the trajectories. We survey recent research efforts that use spatio-temporal data from team sports as input, and involve non-trivial computation. This article categorises the research efforts in a coherent framework and identifies a number of open research questions.},
archivePrefix = {arXiv},
arxivId = {1602.06994},
author = {Gudmundsson, Joachim and Horton, Michael},
doi = {10.1145/3054132},
eprint = {1602.06994},
file = {:home/andrew/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gudmundsson, Horton - 2017 - Spatio-Temporal Analysis of Team Sports.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
keywords = {A.1,Computer Science - Other Computer Science,Folder - lit{\_}spatiotemporal,H.2.8},
mendeley-tags = {A.1,Computer Science - Other Computer Science,Folder - lit{\_}spatiotemporal,H.2.8},
month = {apr},
number = {2},
pages = {1--34},
title = {{Spatio-Temporal Analysis of Team Sports}},
url = {http://arxiv.org/abs/1602.06994{\%}0Ahttp://dx.doi.org/10.1145/3054132 http://dl.acm.org/citation.cfm?doid=3071073.3054132},
volume = {50},
year = {2017}
}
